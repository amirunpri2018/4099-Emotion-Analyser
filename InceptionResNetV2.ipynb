{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GhXVQAigS4L8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "EMOTIONS = [\n",
    "    \"angry\",\n",
    "    \"calm\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"sad\",\n",
    "    \"happy\",\n",
    "    \"neutral\",\n",
    "    \"surprise\"\n",
    "]\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = 100, 100\n",
    "SEQ_LENGTH = 2\n",
    "OVERLAP_IDX = int(0.9 * SEQ_LENGTH)\n",
    "SEQUENCE_PATH = 'sequence/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lG3Lw5U3S4MA"
   },
   "outputs": [],
   "source": [
    "model = InceptionResNetV2(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88HMmU5zS4MC"
   },
   "outputs": [],
   "source": [
    "def extract_feature_sequence():\n",
    "    X, y = [], []\n",
    "    for emotion in EMOTIONS:\n",
    "        video_list = [f for f in os.listdir(DATA_PATH + emotion)]\n",
    "        for video in video_list:\n",
    "            video_path = DATA_PATH + emotion + '/' + video + '/' + video + '_aligned'\n",
    "            frames = [f for f in os.listdir(video_path) if os.path.isfile(os.path.join(video_path, f))]\n",
    "            if len(frames) >= SEQ_LENGTH:\n",
    "                X, y = process_frames(frames, video_path, emotion, X, y)\n",
    "        print('{} sequences extracted'.format(emotion))\n",
    "    # use onehot encoding for LSTM\n",
    "    if SEQ_LENGTH > 1:\n",
    "        y = to_categorical(y, num_classes=len(EMOTIONS))\n",
    "    # save to binary files\n",
    "    print('Saving sequence')\n",
    "    if SEQ_LENGTH == 1:\n",
    "        np.save(SINGLE_PATH + 'X_InceptionResNetV2', X)\n",
    "        np.save(SINGLE_PATH + 'y_InceptionResNetV2', y)\n",
    "    else:\n",
    "        np.save(SEQUENCE_PATH + 'X_InceptionResNetV2', X)\n",
    "        np.save(SEQUENCE_PATH + 'y_InceptionResNetV2', y)\n",
    "\n",
    "\n",
    "def process_frames(frames, video_path, emotion, X, y):\n",
    "    sequence = []\n",
    "    for frame in frames:\n",
    "        frame = video_path + '/' + frame\n",
    "        features = extract_features(model, frame)\n",
    "        sequence.append(features)\n",
    "        if len(sequence) == SEQ_LENGTH:\n",
    "            X.append(sequence)\n",
    "            y.append(EMOTIONS.index(emotion))\n",
    "            # no overlapping frames if sequence length is less than 2\n",
    "            if SEQ_LENGTH > 1:\n",
    "                sequence = sequence[OVERLAP_IDX:]\n",
    "            else:\n",
    "                sequence = []\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def extract_features(model, image_path):\n",
    "    # load and preprocess the frame\n",
    "    print(image_path)\n",
    "    img = image.load_img(image_path, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    # Get the prediction.\n",
    "    features = model.predict(x)\n",
    "    features = features[0]\n",
    "    return features\n",
    "\n",
    "# extract_feature_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8qeuoY0S4ME"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(X, y, test_size=0.2, val_split=True):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "    if val_split:\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    else:\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "def load_sequence():\n",
    "    X = np.load(SEQUENCE_PATH + 'X_InceptionResNetV2.npy')\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2] * X.shape[3] * X.shape[4])\n",
    "    y = np.load(SEQUENCE_PATH + 'y_InceptionResNetV2.npy')\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split_dataset(X, y, test_size=0.2)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xh4qNTACS4MG"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLAZuiWPS4MJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', float_display='.4f', cmap=plt.cm.Greens, class_names=None):\n",
    "    # create confusion matrix plot\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels(class_names)\n",
    "    plt.yticks(tick_marks)\n",
    "    ax.set_yticklabels(class_names)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], float_display),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "\n",
    "def get_predictions_and_labels(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in range(len(y)):\n",
    "        label = list(y[i]).index(1)\n",
    "        pred = list(predictions[i])\n",
    "        max_value = max(pred)\n",
    "        max_index = pred.index(max_value)\n",
    "        p = max_index\n",
    "        y_true.append(label)\n",
    "        y_pred.append(p)\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwt7_3drS4ML"
   },
   "outputs": [],
   "source": [
    "class LSTMNetwork:\n",
    "    def __init__(self, n_layer, lstm_unit, input_shape, feature, data_type):\n",
    "        DATA = load_var()\n",
    "        self.EMOTIONS = DATA['EMOTIONS']\n",
    "\n",
    "        self.model = Sequential()\n",
    "        if n_layer > 1:\n",
    "            self.model.add(LSTM(lstm_unit, return_sequences=True, input_shape=input_shape,\n",
    "                                dropout=0.2))\n",
    "            layer_count = 1\n",
    "            while layer_count < n_layer:\n",
    "                if layer_count == n_layer - 1:\n",
    "                    self.model.add(LSTM(lstm_unit, return_sequences=False, dropout=0.2))\n",
    "                else:\n",
    "                    self.model.add(LSTM(lstm_unit, return_sequences=True, dropout=0.2))\n",
    "                layer_count += 1\n",
    "        else:\n",
    "            self.model.add(LSTM(lstm_unit, return_sequences=False, input_shape=input_shape,\n",
    "                                dropout=0.2))\n",
    "        nb_class = len(self.EMOTIONS)\n",
    "        self.model.add(Dense(nb_class, activation='softmax'))\n",
    "\n",
    "        current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.base_dir = 'LSTM/' + data_type + '/' + feature + '/'\n",
    "        self.model_dir = 'LSTM_' + str(n_layer) + '_' + str(lstm_unit) + '_' + current_time + '/'\n",
    "        filename = 'LSTM.h5'\n",
    "        self.model_file = self.base_dir + self.model_dir + filename\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size):\n",
    "        # compile and train the model\n",
    "        if not os.path.exists(self.base_dir + self.model_dir):\n",
    "            os.makedirs(self.base_dir + self.model_dir)\n",
    "        log_dir = self.base_dir + self.model_dir + 'log/'\n",
    "        os.mkdir(log_dir)\n",
    "        self.model.compile(optimizer='adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "        callbacks = [ModelCheckpoint(self.model_file, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "                     TensorBoard(log_dir=log_dir, write_graph=True)]\n",
    "        self.model.fit(X_train, y_train,\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       validation_data=(X_val, y_val),\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        # evaluate_vgg16 the model with validation set\n",
    "        model = load_model(self.model_file)\n",
    "        scores = model.evaluate(X_val, y_val)\n",
    "        print('val_loss: {}, val_acc: {}'.format(scores[0], scores[1]))\n",
    "\n",
    "        y_true, y_pred = get_predictions_and_labels(model, X_val, y_val)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        df = pd.DataFrame(cm_percent, index=self.EMOTIONS, columns=self.EMOTIONS)\n",
    "        df.index.name = 'Actual'\n",
    "        df.columns.name = 'Predicted'\n",
    "        df.to_csv(self.base_dir + self.model_dir + 'cm_val.csv', float_format='%.4f')\n",
    "\n",
    "        # plot percentage confusion matrix\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        plot_confusion_matrix(cm_percent, class_names=self.EMOTIONS)\n",
    "        plt.savefig(self.base_dir + self.model_dir + 'cm_percent_val.png', format='png')\n",
    "        # plot normal confusion matrix\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        plot_confusion_matrix(cm, float_display='.0f', class_names=self.EMOTIONS)\n",
    "        plt.savefig(self.base_dir + self.model_dir + 'cm_val.png', format='png')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def compare_model(self, X_val, y_val):\n",
    "        folder_list = [model_dir for model_dir in os.listdir(self.base_dir) if 'LSTM' in model_dir]\n",
    "        for folder in folder_list:\n",
    "            filename = 'LSTM.h5'\n",
    "            path = os.path.join(self.base_dir, folder, filename)\n",
    "            model = load_model(path)\n",
    "            scores = model.evaluate(X_val, y_val)\n",
    "            print('model: {}, val_loss: {}, val_acc: {}'.format(folder, scores[0], scores[1]))\n",
    "\n",
    "            y_true, y_pred = get_predictions_and_labels(model, X_val, y_val)\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "            # plot percentage confusion matrix\n",
    "            fig1, ax1 = plt.subplots()\n",
    "            plot_confusion_matrix(cm_percent, class_names=self.EMOTIONS)\n",
    "            plt.savefig(os.path.join(self.base_dir, folder, 'cm_percent_test.png'), format='png')\n",
    "            # plot normal confusion matrix\n",
    "            fig2, ax2 = plt.subplots()\n",
    "            plot_confusion_matrix(cm, float_display='.0f', class_names=self.EMOTIONS)\n",
    "            plt.savefig(os.path.join(self.base_dir, folder, 'cm_test.png'), format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvNNCgJ7S4MN"
   },
   "outputs": [],
   "source": [
    "feature = 'InceptionResNetV2'\n",
    "data_type = 'Basic'\n",
    "n_layer = 1\n",
    "lstm_unit = 32\n",
    "batch_size = 256\n",
    "epochs = 250\n",
    "lstm_net = LSTMNetwork(n_layer, lstm_unit, X_train.shape[1:], feature, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xk2XySYaS4MP"
   },
   "outputs": [],
   "source": [
    "lstm_net.train(X_train, y_train, X_test, y_test, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HxDxzTKS4MV"
   },
   "outputs": [],
   "source": [
    "lstm_net.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDqyHRXqS4MZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "InceptionResNetV2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
